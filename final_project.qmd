---
title: "ADS Final Project"
format:
  html:
    theme: darkly
    toc: true
    number-sections: false
---

```{r include=FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)
library(qqplotr)
library(patchwork)
library(ggpmisc)
library(AICcmodavg)
```


# Loading data
```{r}

# Employees data
employees <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Agriculture%20Employees%20/employ.csv")

# Climate change data

rainfall <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Climate%20Change/rainfall.csv")

temp <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Climate%20Change/temp.csv")

# Pesticides data

pesticides <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Climate%20Change/pesticides.csv")


# Land Use data

land_use <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Land%20Use%20/fao_data_land_data.csv")

# Population data
pop <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Population/population_by_country.csv")


# Producer price data
price <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Producer%20Price/Producer_Prices.csv")

# Agriculture yield data
yield <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Yield/yield.csv")
```


```{r}
# First 6 rows of each table
head(employees)
head(land_use)
head(pesticides)
head(pop)
head(price)
head(rainfall)
head(temp)
head(yield)
```

Some of the tables have unnecessary columns, deleting those columns is a crucial before starting asking questions about the data

# Data Cleaning & Arranging
```{r}

# Country & Year columns uniformity
colnames(employees)[1] <- "Country"
colnames(land_use)[c(1,4,6)] <- c("Country","Year","land_price")
colnames(pesticides)[c(2,7)] <- c("Country", "pesticides_amount")
colnames(pop)[c(2,3,4)] <- c("Country","Year","pop_amount")
colnames(price)[c(4,14)] <- c("Country","crop_price")
colnames(rainfall)[c(1,3)] <- c("Country","avg_rainfall")
colnames(temp)[1:2] <- c("Year","Country")
colnames(yield)[c(4,12)] <- c("Country",'yield')


# Remove unnecessary columns and arrange each table by Country & Year

employees <- employees |>
  arrange(Country, Year)

# Remove plus sign from country name
land_use$Country <- sapply(land_use$Country, function(x) gsub(' \\+', '', x))

require(dplyr)
land_use <- land_use |>
  filter(category %in% c("agricultural_area")) |>
  select(-c(category,unit,element,element_code, value_footnotes)) |>
  arrange(Country, Year)

pesticides <- pesticides |>
  select(-c(Unit,Element, Domain,Item)) |>
  arrange(Country, Year)

pop <- pop |>
  select(-country_code) |>
  arrange(Country, Year)

# Change Maize(corn) to Maize only
price$Item <- sapply(price$Item, function(x) gsub('corn', '', x)) %>%
  sapply(., function(x) gsub('\\()', '', x))

price <- price |>
  select(-c(Domain.Code,Domain,Area.Code..M49.,Element.Code,Element,
            Item.Code..CPC.,Year.Code,Months.Code,Unit,Flag, Flag.Description, Months)) |>
  arrange(Country, Year,Item) |>
  select(-Item)

rainfall <- rainfall |>
  arrange(Country, Year)

temp <- temp |>
  arrange(Country, Year)

yield <- yield |>
  select(-c(Domain, Domain.Code,Area.Code,Element.Code,
            Element,Item.Code,Year.Code,Unit)) |>
  arrange(Country, Year,Item)
```

After deleting unnecessary columns, changing column names, filtering the relevant countries and sorting the tables. It's time to join all of the tables into one big table.

```{r}
# Join tables
joined_tables <- yield %>%
  left_join(land_use,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(pesticides,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(pop,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(rainfall,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(temp,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(employees,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(price, by=c("Year","Country"), relationship='many-to-many') |>
  arrange(Country, Year)

# Reordering columns
joined_tables <- joined_tables |>  select(Year, Country, pop_amount,number_employed_agri,avg_temp, avg_rainfall,land_price,Item, pesticides_amount, crop_price,yield)
```

```{r}
# Removing countries that have more than 80% missing values
joined_tables <- joined_tables |>
  group_by(Country) |>
  mutate(missing_values_crop = sum(is.na(crop_price)),
         missing_values_employee = sum(is.na(number_employed_agri)),
            observations=n()) |>
  ungroup() |>
  filter(!((missing_values_crop/observations > 0.8) | (missing_values_employee/observations > 0.8))) |>
  select(-c(missing_values_crop,missing_values_employee, observations))
```

Our goal is to use mean based analysis in order to find which of the indices affect the most on crop yield outcome. Therefore, we used mean imputation to fill the missing values in each column. However, we still saved our data frame before the imputation.
```{r}
filled_with_avg <- joined_tables |>
  group_by(Country) |>
  # Replace missing values with the column avg by country.
  mutate_at(vars(-group_cols(), -avg_rainfall),~ ifelse(is.na(.), mean(., na.rm=T),.)) |>
  # Fill avg_rainfall backwards
  fill(avg_rainfall, .direction='up') |>
  ungroup()

filled_with_avg$avg_rainfall <- as.integer(filled_with_avg$avg_rainfall)
```


# Data Visualization

## Scatter plots
```{r warning=FALSE}
filled_with_avg |>
  filter(!is.na(pop_amount)) |>
  group_by(Country) |>
  summarize(avg_pop = mean(pop_amount), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_pop + 1), y=log(avg_yield + 1), color=avg_yield)) +
  geom_point() + 
  geom_smooth(formula = y~x, method='lm') + 
  labs(title='Avg crop yield VS Avg Population  (Log Scaled)',
       x='log(avg population)',
       y='log(avg crop yield)')

filled_with_avg |>
  filter(!is.na(number_employed_agri)) |>
  group_by(Country) |>
  summarize(avg_employees = mean(number_employed_agri), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_employees + 1), y=log(avg_yield + 1), color=avg_yield)) +
  geom_point() + 
  geom_smooth(formula = y~x, method='lm') + 
  labs(title='Avg crop yield VS Avg Num of Employees (Log Scaled)',
       x='log(avg employees)',
       y='log(avg crop yield)')

filled_with_avg |>
  filter(!is.na(avg_temp)) |>
  group_by(Country) |>
  summarize(avg_temp =  mean(avg_temp), avg_yield = mean(yield)) |>
  ggplot(aes(x=avg_temp, y=avg_yield, color=avg_yield)) +
  geom_point() + 
  geom_smooth(formula = y~x, method='lm') + 
  labs(title='Avg crop yield VS Avg Temperature')

filled_with_avg |>
  filter(!is.na(avg_rainfall)) |>
  group_by(Country) |>
  summarize(avg_rainfall = mean(avg_rainfall), avg_yield = mean(yield)) |>
  ggplot(aes(x=avg_rainfall, y=avg_yield, color=avg_yield)) + 
  geom_point() + 
  geom_smooth(formula = y~x, method='lm') + 
  labs(title = 'Avg crop yield VS Avg rainfall')

filled_with_avg |>
  filter(!is.na(land_price)) |>
  group_by(Country) |>
  summarize(avg_land_price = mean(land_price), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_land_price + 1), y=log(avg_yield + 1), color=avg_yield)) + 
  geom_point() + 
  geom_smooth(formula = y~x, method='lm') + 
  labs(title = 'Avg crop yield VS Avg Land price (Log Scaled)',
       x='log(avg land price)',
       y='log(avg crop yield)')

filled_with_avg |>
  filter(!is.na(pesticides_amount)) |>
  group_by(Country) |>
  summarize(avg_pesticides = mean(pesticides_amount), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_pesticides + 1), y=log(avg_yield + 1), color=avg_yield)) + 
  geom_point() + 
  geom_smooth(formula = y~x, method='lm') + 
  labs(title = 'Avg crop yield VS Avg Pesticides amount (Log Scaled)',
       x='log(avg pesticides)',
       y='log(avg crop yield)')

filled_with_avg |>
  filter(!is.na(crop_price)) |>
  group_by(Country) |>
  summarize(avg_crop_price = mean(pesticides_amount), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_crop_price + 1), y=log(avg_yield + 1), color=avg_yield)) + 
  geom_point() + 
  geom_smooth(formula = y~x, method='lm') + 
  labs(title = 'Avg crop yield VS Avg Crop price (Log Scaled)',
       x='log(avg crop price)',
       y='log(avg crop yield)')



```
# Distribution plot

Determine the distribution of our response variable "yield"
```{r}
yield_hist <- filled_with_avg |>
  na.omit() |>
  ggplot(aes(x=yield)) + 
  geom_histogram(fill="#69b3a2", color="#e9ecef", alpha=0.8,bins=30)+
  theme(axis.text.x = element_text(angle=20, hjust=0.5))

yield_hist_log <- filled_with_avg |>
  na.omit() |>
  ggplot(aes(x=log(yield + 1))) + 
  geom_histogram(fill="#69b3a2", color="#e9ecef", alpha=0.8,bins=30)+
  labs(x = 'log(yield)') + 
  theme(axis.text.x = element_text(angle=20, hjust=0.5),
        axis.title.y = element_blank())

yield_hist_sqrt <- filled_with_avg |>
  na.omit() |>
  ggplot(aes(x=sqrt(yield))) +
  geom_histogram(fill="#69b3a2", color="#e9ecef", alpha=0.8,bins=30) + 
  theme(axis.text.x = element_text(angle=20, hjust=0.5),
        axis.title.y = element_blank())
  

yield_hist + yield_hist_log + yield_hist_sqrt + plot_annotation(
  title = 'Response Variable Distribution (Yield)',
  theme = theme(plot.title = element_text(hjust=0.5))
)
  
```
The log version of our response variable looks like it might have a normal distribution, however this needs to be tested using a statistical test. We will use Kolmogorov-Smirnov test since our data is too large for d'Agonisto & Shapiro.

```{r warning=FALSE}

df <- na.omit(filled_with_avg)

ks.test(df$yield, 'pnorm')
ks.test(log(df$yield), 'pnorm')
ks.test(sqrt(df$yield), 'pnorm')


```

Data is not normal,therefore it might have some other distribution. We do know that our data has a positive skew which indicates it might has a negative binomial / geometric /  exponential / gamma / poisson distribution. However, since our data is discrete it can only has a discrete distribution, in addition the data is count data which means it'll could fit negative binomial distribution or poisson distribution.


```{r}
# Compare mean to variance
var(filled_with_avg$yield)/mean(filled_with_avg$yield)
```
Since its bigger than one our data might exhibits over dispersion (Variance > Mean).

```{r}
filled_with_avg$yield <- as.numeric(filled_with_avg$yield)

# Creating groups
yield_groups <- filled_with_avg |>
  na.omit() |>
  select(yield) |>
  mutate(group = ntile(yield, 100)) |>
  group_by(group) |>
  mutate(mean = floor(mean(yield)), variance = floor(var(yield))) |>
  select(group, mean , variance) |>
  distinct(group, .keep_all = T) |>
  arrange(group)


```
After calculating the mean & variance of each group we can now try to fit a poisson regression on the data.

```{r}
fit_poi <- glm(variance ~ mean, data= yield_groups, family = poisson(link='log'))
summary(fit_poi)

fit_poi$deviance/fit_poi$rank
```
Since the deviance/degrees of freedom is bigger our model underestimate the standard error and thus the p value is small. Therefore, the poisson regression might not be the best fit to our data and we thus need to try fitting a quasi poisson or a negative binomial regression, since these two types of regression are used when the data is count and the poisson regression is underestimating the standard error of the model.

The Quasi Poisson model assumes that $Var(X) = \theta * Mean(X)$
The Negative Binomial model assumes that $Var(X) = Mean(X) + Mean(X)^2/k$

```{r}
# Quasi poisson model
fit_qpoi <- glm(variance ~ mean, data=yield_groups, family = quasipoisson(link='log'))
summary(fit_qpoi)

cat("Quasi Poisson R^2:", 1 - fit_qpoi$deviance/fit_qpoi$null.deviance)
```

```{r}
# Negative binomial model
fit_nb <- MASS::glm.nb(variance ~ mean, data= yield_groups)
summary(fit_nb)

cat("NegBin R^2:", 1 - fit_nb$deviance/fit_nb$null.deviance)
```


```{r}
# Residual Analysis
nb_pred <- predict(fit_nb, newdata = yield_groups, type = 'response')
qpoi_pred <- predict(fit_qpoi, newdata = yield_groups, type = 'response')

yield_groups$qpoi_pred <- qpoi_pred
yield_groups$nb_pred <- nb_pred

yield_groups <- yield_groups |>
  mutate(
    qpoi_resid = variance  - qpoi_pred,
    nb_resid = variance - nb_pred
  )

poi_resid_plot <- yield_groups |>
  ggplot(aes(x=qpoi_pred, y=qpoi_resid)) +
  geom_point()+
  geom_hline(yintercept=0,linetype='dashed', color='red')

nb_resid_plot <- yield_groups |>
  ggplot(aes(x=nb_pred, y=nb_resid)) +
  geom_point() + 
  geom_hline(yintercept=0, linetype='dashed', color='red')

poi_resid_plot + nb_resid_plot + plot_annotation(
  title = 'Residual Analysis'
)
yield_groups |>
  ggplot(aes(x=mean, y=variance)) +
  geom_point() + 
  geom_line(aes(x=mean, y=nb_pred, color= 'Negative Binomial'))+
  geom_line(aes(x=mean, y=qpoi_pred, color = 'Quasi Poisson')) + 
  labs(x = 'Mean', y='Variance', colour = 'Models', title = 'Real Values Vs Predicted Values (NB vs QPoi)')  + 
  geom_text(x=50000,y=1.5e+09,label = paste("NB R^2: ", round(1 - fit_nb$deviance/fit_nb$null.deviance, 2))) + 
  geom_text(x=50000, y=1.3e+09, label = paste("QPoi R^2: ", round(1 - fit_qpoi$deviance/fit_qpoi$null.deviance, 3)))
```
The plot we created compares the real values vs the predicted ones of each model.By observing the plot we can clearly tell that the quasi poisson model is better at predicting & explaining our data than the negative binomial model. In addition, we also created a residual plot for our residual analysis in order to determine which model fits the overall trend of the data however, both models seems to fit the overall trend of the data. 

By both plots examinations we decided that our response variable distribution is Quasi Poisson.
```{r}

```













