---
title: "ADS Final Project"
format:
  html:
    theme: darkly
    toc: true
    number-sections: false
---

```{r include=FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)
library(qqplotr)
library(patchwork)
library(ggpmisc)
library(corrplot)
library(Kendall)
```


# Loading data
```{r}

# Employees data
employees <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Agriculture%20Employees%20/employ.csv")

# Climate change data

rainfall <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Climate%20Change/rainfall.csv")

temp <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Climate%20Change/temp.csv")

# Pesticides data

pesticides <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Climate%20Change/pesticides.csv")


# Land Use data

land_use <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Land%20Use%20/fao_data_land_data.csv")

# Population data
pop <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Population/population_by_country.csv")


# Producer price data
price <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Producer%20Price/Producer_Prices.csv")

# Agriculture yield data
yield <- read.csv("https://raw.githubusercontent.com/erezlid/ADS_Final_Project/main/Data/Yield/yield.csv")
```


```{r}
# First 6 rows of each table
head(employees)
head(land_use)
head(pesticides)
head(pop)
head(price)
head(rainfall)
head(temp)
head(yield)


```
Some of the tables have unnecessary columns, deleting those columns is a crucial before starting asking questions about the data

# Data Cleaning & Arranging
```{r}

# Country & Year columns uniformity
colnames(employees)[1] <- "Country"
colnames(land_use)[c(1,4,6)] <- c("Country","Year","land_price")
colnames(pesticides)[c(2,7)] <- c("Country", "pesticides_amount")
colnames(pop)[c(2,3,4)] <- c("Country","Year","pop_amount")
colnames(price)[c(4,14)] <- c("Country","crop_price")
colnames(rainfall)[c(1,3)] <- c("Country","avg_rainfall")
colnames(temp)[1:2] <- c("Year","Country")
colnames(yield)[c(4,12)] <- c("Country",'yield')


# Remove unnecessary columns and arrange each table by Country & Year

employees <- employees |>
  arrange(Country, Year)

# Remove plus sign from country name
land_use$Country <- sapply(land_use$Country, function(x) gsub(' \\+', '', x))

require(dplyr)
land_use <- land_use |>
  filter(category %in% c("agricultural_area")) |>
  select(-c(category,unit,element,element_code, value_footnotes)) |>
  arrange(Country, Year)

pesticides <- pesticides |>
  select(-c(Unit,Element, Domain,Item)) |>
  arrange(Country, Year)

pop <- pop |>
  select(-country_code) |>
  arrange(Country, Year)

# Change Maize(corn) to Maize only
price$Item <- sapply(price$Item, function(x) gsub('corn', '', x)) %>%
  sapply(., function(x) gsub('\\()', '', x))

price <- price |>
  select(-c(Domain.Code,Domain,Area.Code..M49.,Element.Code,Element,
            Item.Code..CPC.,Year.Code,Months.Code,Unit,Flag, Flag.Description, Months)) |>
  arrange(Country, Year,Item) |>
  select(-Item)

rainfall <- rainfall |>
  arrange(Country, Year)

temp <- temp |>
  arrange(Country, Year)

yield <- yield |>
  select(-c(Domain, Domain.Code,Area.Code,Element.Code,
            Element,Item.Code,Year.Code,Unit)) |>
  arrange(Country, Year,Item)
```

After deleting unnecessary columns, changing column names, filtering the relevant countries and sorting the tables. It's time to join all of the tables into one big table.

```{r}
# Join tables
joined_tables <- yield %>%
  left_join(land_use,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(pesticides,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(pop,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(rainfall,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(temp,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(employees,by=c("Year","Country"), relationship = "many-to-many") |>
  left_join(price, by=c("Year","Country"), relationship='many-to-many') |>
  arrange(Country, Year)

# Reordering columns
joined_tables <- joined_tables |>  select(Year, Country, pop_amount,number_employed_agri,avg_temp, avg_rainfall,land_price,Item, pesticides_amount, crop_price,yield)
```

```{r}
# Removing countries that have more than 80% missing values
joined_tables <- joined_tables |>
  group_by(Country) |>
  mutate(missing_values_crop = sum(is.na(crop_price)),
         missing_values_employee = sum(is.na(number_employed_agri)),
            observations=n()) |>
  ungroup() |>
  filter(!((missing_values_crop/observations > 0.8) | (missing_values_employee/observations > 0.8))) |>
  select(-c(missing_values_crop,missing_values_employee, observations))
```

Our goal is to use mean based analysis in order to find which of the indices affect the most on crop yield outcome. Therefore, we used mean imputation to fill the missing values in each column. However, we still saved our data frame before the imputation.
```{r}
filled_with_avg <- joined_tables |>
  group_by(Country) |>
  # Replace missing values with the column avg by country.
  mutate_at(vars(-group_cols(), -avg_rainfall),~ ifelse(is.na(.), mean(., na.rm=T),.)) |>
  # Fill avg_rainfall backwards
  fill(avg_rainfall, .direction='up') |>
  ungroup()

filled_with_avg$avg_rainfall <- as.integer(filled_with_avg$avg_rainfall)
```


# Data Visualization

## Scatter plots
```{r warning=FALSE}
filled_with_avg |>
  filter(!is.na(pop_amount)) |>
  group_by(Country) |>
  summarize(avg_pop = mean(pop_amount), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_pop + 1), y=log(avg_yield + 1), color=avg_yield)) +
  geom_point() + 
  geom_smooth(formula = y~x, method='glm') + 
  labs(title='Avg crop yield VS Avg Population  (Log Scaled)',
       x='log(avg population)',
       y='log(avg crop yield)')

filled_with_avg |>
  filter(!is.na(number_employed_agri)) |>
  group_by(Country) |>
  summarize(avg_employees = mean(number_employed_agri), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_employees + 1), y=log(avg_yield + 1), color=avg_yield)) +
  geom_point() + 
  geom_smooth(formula = y~x, method='glm') + 
  labs(title='Avg crop yield VS Avg Num of Employees (Log Scaled)',
       x='log(avg employees)',
       y='log(avg crop yield)')

filled_with_avg |>
  filter(!is.na(avg_temp)) |>
  group_by(Country) |>
  summarize(avg_temp =  mean(avg_temp), avg_yield = mean(yield)) |>
  ggplot(aes(x=avg_temp, y=avg_yield, color=avg_yield)) +
  geom_point() + 
  geom_smooth(formula = y~x, method='glm') + 
  labs(title='Avg crop yield VS Avg Temperature')

filled_with_avg |>
  filter(!is.na(avg_rainfall)) |>
  group_by(Country) |>
  summarize(avg_rainfall = mean(avg_rainfall), avg_yield = mean(yield)) |>
  ggplot(aes(x=avg_rainfall, y=avg_yield, color=avg_yield)) + 
  geom_point() + 
  geom_smooth(formula = y~x, method='glm') + 
  labs(title = 'Avg crop yield VS Avg rainfall')

filled_with_avg |>
  filter(!is.na(land_price)) |>
  group_by(Country) |>
  summarize(avg_land_price = mean(land_price), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_land_price + 1), y=log(avg_yield + 1), color=avg_yield)) + 
  geom_point() + 
  geom_smooth(formula = y~x, method='glm') + 
  labs(title = 'Avg crop yield VS Avg Land price (Log Scaled)',
       x='log(avg land price)',
       y='log(avg crop yield)')

filled_with_avg |>
  filter(!is.na(pesticides_amount)) |>
  group_by(Country) |>
  summarize(avg_pesticides = mean(pesticides_amount), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_pesticides + 1), y=log(avg_yield + 1), color=avg_yield)) + 
  geom_point() + 
  geom_smooth(formula = y~x, method='glm') + 
  labs(title = 'Avg crop yield VS Avg Pesticides amount (Log Scaled)',
       x='log(avg pesticides)',
       y='log(avg crop yield)')

filled_with_avg |>
  filter(!is.na(crop_price)) |>
  group_by(Country) |>
  summarize(avg_crop_price = mean(pesticides_amount), avg_yield = mean(yield)) |>
  ggplot(aes(x=log(avg_crop_price + 1), y=log(avg_yield + 1), color=avg_yield)) + 
  geom_point() + 
  geom_smooth(formula = y~x, method='lm') + 
  labs(title = 'Avg crop yield VS Avg Crop price (Log Scaled)',
       x='log(avg crop price)',
       y='log(avg crop yield)')



```
# Distribution plot

Determine the distribution of our response variable "yield"
```{r}
yield_hist <- filled_with_avg |>
  na.omit() |>
  ggplot(aes(x=yield)) + 
  geom_histogram(fill="#69b3a2", color="#e9ecef", alpha=0.8,bins=30)+
  theme(axis.text.x = element_text(angle=20, hjust=0.5))

yield_hist_log <- filled_with_avg |>
  na.omit() |>
  ggplot(aes(x=log(yield + 1))) + 
  geom_histogram(fill="#69b3a2", color="#e9ecef", alpha=0.8,bins=30)+
  labs(x = 'log(yield)') + 
  theme(axis.text.x = element_text(angle=20, hjust=0.5),
        axis.title.y = element_blank())

yield_hist_sqrt <- filled_with_avg |>
  na.omit() |>
  ggplot(aes(x=sqrt(yield))) +
  geom_histogram(fill="#69b3a2", color="#e9ecef", alpha=0.8,bins=30) + 
  theme(axis.text.x = element_text(angle=20, hjust=0.5),
        axis.title.y = element_blank())
  

yield_hist + yield_hist_log + yield_hist_sqrt + plot_annotation(
  title = 'Response Variable Distribution (Yield)',
  theme = theme(plot.title = element_text(hjust=0.5))
)
  
```
The log version of our response variable looks like it might have a normal distribution, however this needs to be tested using a statistical test. We will use Kolmogorov-Smirnov test since our data is too large for d'Agonisto & Shapiro.

```{r warning=FALSE}

df <- na.omit(filled_with_avg)

ks.test(df$yield, 'pnorm')
ks.test(log(df$yield), 'pnorm')
ks.test(sqrt(df$yield), 'pnorm')


```

Data is not normal,therefore it might have some other distribution. We do know that our data has a positive skew which indicates it might has a negative binomial / geometric /  exponential / gamma / poisson distribution. However, since our data is discrete it can only has a discrete distribution, in addition the data is count data which means it'll could fit negative binomial distribution or poisson distribution.


```{r}
# Compare mean to variance
var(filled_with_avg$yield)/mean(filled_with_avg$yield)
```
Since its bigger than one our data might exhibits over dispersion (Variance > Mean).

```{r}
filled_with_avg$yield <- as.numeric(filled_with_avg$yield)

# Creating groups
yield_groups <- filled_with_avg |>
  na.omit() |>
  select(yield) |>
  mutate(group = ntile(yield, 30)) |>
  group_by(group) |>
  mutate(mean = floor(mean(yield)), variance = floor(var(yield))) |>
  select(group, mean , variance) |>
  distinct(group, .keep_all = T) |>
  arrange(group)


```
When it comes to linear models, we usualy model over dispersed data using the Quasi Poisson model or the Negative Binomial model.

The Quasi Poisson model assumes that $Var(X) = \theta * Mean(X)$
The Negative Binomial model assumes that $Var(X) = Mean(X) + Mean(X)^2/k$

In order to find the family distribution that fit the data the most we separated the data into 30 groups and calculated each group mean and variance, then we fit a GLM model in order to find the right family distribution. 

```{r}
# Quasi poisson model
fit_qpoi <- glm(variance ~ mean, data=yield_groups, family = quasipoisson(link='log'))
summary(fit_qpoi)

cat("Quasi Poisson R^2:", 1 - fit_qpoi$deviance/fit_qpoi$null.deviance)
```

```{r}
# Negative binomial model
fit_nb <- MASS::glm.nb(variance ~ mean, data= yield_groups, control = glm.control(maxit=1e10))

summary(fit_nb)

cat("NegBin R^2:", 1 - fit_nb$deviance/fit_nb$null.deviance)
```


```{r}
# Residual Analysis
nb_pred <- predict(fit_nb, newdata = yield_groups, type = 'response')
qpoi_pred <- predict(fit_qpoi, newdata = yield_groups, type = 'response')

yield_groups$qpoi_pred <- qpoi_pred
yield_groups$nb_pred <- nb_pred

yield_groups <- yield_groups |>
  mutate(
    qpoi_resid = variance  - qpoi_pred,
    nb_resid = variance - nb_pred
  )

poi_resid_plot <- yield_groups |>
  ggplot(aes(x=qpoi_pred, y=qpoi_resid)) +
  geom_point()+
  geom_hline(yintercept=0,linetype='dashed', color='red')

nb_resid_plot <- yield_groups |>
  ggplot(aes(x=nb_pred, y=nb_resid)) +
  geom_point() + 
  geom_hline(yintercept=0, linetype='dashed', color='red')

poi_resid_plot + nb_resid_plot + plot_annotation(
  title = 'Residual Analysis'
)
yield_groups |>
  ggplot(aes(x=mean, y=variance)) +
  geom_point() + 
  geom_line(aes(x=mean, y=nb_pred, color= 'Negative Binomial'))+
  geom_line(aes(x=mean, y=qpoi_pred, color = 'Quasi Poisson')) + 
  labs(x = 'Mean', y='Variance', colour = 'Models', title = 'Real Values Vs Predicted Values (NB vs QPoi)')  + 
  geom_text(x=50000,y=2e+09,label = paste("NB R^2: ", round(1 - fit_nb$deviance/fit_nb$null.deviance, 2))) + 
  geom_text(x=50000, y=1.8e+09, label = paste("QPoi R^2: ", round(1 - fit_qpoi$deviance/fit_qpoi$null.deviance, 3)))
```
We created a plot that compares the real values with the predicted values from each model. Upon observing the plot, it is evident that the quasi-Poisson model performs better in predicting and explaining the data compared to the negative binomial model. Furthermore, both models appear to adequately fit the data based on the analysis of the residuals, as the majority of the residuals cluster around zero. However, when considering the dispersion parameter, the Negative Binomial model outperforms the Quasi Poisson model indicating a better fit to the data. Therefore, based of this analysis, it won't matter what model we'll choose to use.


## Correlation Analysis
```{r}
agri_df <- filled_with_avg |>
  na.omit()

corel <- agri_df |>
  select(-yield) |>
  select_if(is.numeric) |>
  lapply(function(col) cor.test(col,agri_df$yield,method='spearman',exact=F))

```

| Variable                 | P-value  | rho        | 
| ------------------------ |----------|------------|
| Population               | 2.2e-16  |0.02524405  |
| Employees in agriculture | 2.2e-16  |-0.1049963  |
| Avg Temp                 | 2.2e-16  |-0.09457474 |
| Avg Rainfall             | 2.2e-16  |0.05122064  |
| Land price               | 0.001354 |0.007765627 |
| Pesticides               | 2.2e-16  |0.1296358   |
| Crop Price               | 2.2e-16  |0.07438538  |
| Year                     | 2.2e-16  |0.152361    |

: Spearman's Rank Correlation Test Results


Each p-value in the table is lower than 0.05 thus, we can say that every numeric variable in the data is correlated with the yield variable. However, the rho values are relatively small which means that the monotonic relation between the variables in the data and the yield variable isn't strong.

## Chisq Test

Since the country column is a categorical variable we can't conduct a correlation test thus, we'll use the chi squared test for independence in order to check if the yield variable is dependent of the country variable.

```{r}

agri_df |>
  select(yield, Country) |>
  group_by(Country) |>
  mutate(total_yield = sum(yield)) |>
  select(Country, total_yield) |>
  with(chisq.test(table(Country, total_yield), simulate.p.value = T))
```






